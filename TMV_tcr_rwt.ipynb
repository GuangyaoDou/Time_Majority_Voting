{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from time import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_search = 1 # the subject id you want to see in the TMV specific output\n",
    "\n",
    "ignore_session_threashold = 0.50\n",
    "data_status = 'old_'\n",
    "data_source = 'tcr'\n",
    "tcr_subject = [7, 112, 113, 121, 75, 107, 79, 82, 118, 76, 115, 117, 119, 120, 105, 78, 124]\n",
    "rwt_subject = [7, 112, 113, 114, 75, 107, 79, 82, 118, 76, 115, 117, 119, 120]\n",
    "new_tcr_trial = [123, 124]\n",
    "subject = None\n",
    "if data_status == \"old_\":\n",
    "    if data_source == 'tcr':\n",
    "        subject = tcr_subject\n",
    "    else:\n",
    "        subject = rwt_subject\n",
    "else:\n",
    "    subject = new_tcr_trial\n",
    "first_chopped_off = 600 * 0.3\n",
    "last_chopped_off = 600 * 0\n",
    "\n",
    "best_classifier_predicted_y = []\n",
    "second_classifier_predicted_y = []\n",
    "\n",
    "LDA = {}\n",
    "GradientBoost = {}\n",
    "NearestNeighbor = {}\n",
    "AdaBoost = {}\n",
    "RandomForest = {}\n",
    "LinearSVM = {}\n",
    "RBFSVM = {}\n",
    "DecisionTree = {}\n",
    "RUSBoost = {}\n",
    "sLDA = {}\n",
    "\n",
    "data_left_for_subjects = {} # records the percentage of data being used for each subject\n",
    "\n",
    "time_continuity_subject = {} # records the time of time_continuity_algorithm for each subject\n",
    "\n",
    "subject_accuracy_best_classifier_dict = {} # records the accuracy of the best classifier for each subject\n",
    "\n",
    "subject_accuracy_tmv_dict = {} # records the accuracy of time_majority_algorithm for each subject\n",
    "\n",
    "subject_preprocess_record = {} # records the number of sessions and folds left for each subjects\n",
    "\n",
    "subject_prediction = {}\n",
    "\n",
    "subject_unknown_percentage = {}\n",
    "\n",
    "time_classifier = {} # records the time it takes for each classifier to execute the 7-fold cross-validation\n",
    "# define models to train\n",
    "names = [  \n",
    "#         'GradientBoostingRegressor',\n",
    "        'LDA',\n",
    "        'Nearest Neighbors',\n",
    "#         'AdaBoostClassifier',\n",
    "        'RandomForest',\n",
    "#         \"Linear SVM\",\n",
    "        \"RBF SVM\",\n",
    "#         \"Decision Tree\",\n",
    "#         'RUSBoost',\n",
    "        'Shrinkage LDA',\n",
    "        ]\n",
    "\n",
    "# build classifiers\n",
    "classifiers = [\n",
    "#             GradientBoostingRegressor(random_state=1),\n",
    "            LinearDiscriminantAnalysis(),\n",
    "            KNeighborsClassifier(n_neighbors=5),\n",
    "#             AdaBoostClassifier(n_estimators=400, learning_rate = 0.6),\n",
    "            RandomForestClassifier(n_estimators=300, max_features = \"sqrt\", oob_score = True),\n",
    "#             SVC(kernel=\"linear\", C=0.025),\n",
    "            SVC(gamma=2, C=1),\n",
    "#             DecisionTreeClassifier(),\n",
    "#             RUSBoostClassifier(n_estimators = 200, random_state=1),\n",
    "            LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "              ]\n",
    "\n",
    "dicts_records = [\n",
    "#                  GradientBoost, \n",
    "                 LDA,\n",
    "                 NearestNeighbor,\n",
    "#                  AdaBoost, \n",
    "                 RandomForest, \n",
    "#                  LinearSVM,\n",
    "                 RBFSVM,\n",
    "#                  DecisionTree,\n",
    "#                  RUSBoost, \n",
    "                 sLDA\n",
    "                ]\n",
    "\n",
    "\n",
    "def check_removed_index(name, removed_dict, index_to_be_removed, lowerBound, upperBound):\n",
    "    if name not in removed_dict:\n",
    "        removed_dict[name] = 0\n",
    "    lst = [i for i in index_to_be_removed if i >= lowerBound and i < upperBound]\n",
    "    removed_dict[name] = removed_dict[name] + len(lst)\n",
    "\n",
    "def calculate_accuracy(y_actual, y_predict):\n",
    "    count = 0\n",
    "    for i in range(len(y_actual)):\n",
    "        if y_actual[i] == y_predict[i]:\n",
    "            count = count + 1\n",
    "    return count / float(len(y_actual))\n",
    "\n",
    "def check_plateau(dataFrame, current_index):\n",
    "    for i in range(current_index + 1, current_index + 14):\n",
    "        if i >= len(dataFrame):\n",
    "            return True\n",
    "        lst = move_data.iloc[current_index, :].tolist()\n",
    "        if sum(lst) != 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def random_output(first, second):\n",
    "    random_num = random.random()\n",
    "    if random_num <= 0.5:\n",
    "        return first\n",
    "    else:\n",
    "        return second\n",
    "\n",
    "print(len(subject))\n",
    "\n",
    "tasks_dict = {} # array of dictionaries\n",
    "for i in range(30):\n",
    "    key_name = \"task\" + str(i+1)\n",
    "#     temp_dict = {}\n",
    "#     temp_dict[key_name] = []\n",
    "#     tasks_dict.append(temp_dict)\n",
    "    tasks_dict[key_name] = []\n",
    "\n",
    "print(tasks_dict)\n",
    "\n",
    "def most_common(List):\n",
    "    return(mode(List))\n",
    "\n",
    "def accuracy_divide(numerator, denominator):\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator / denominator\n",
    "# subject_2_RF = []\n",
    "# subject_3_RF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517dc346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(1, len(subject) + 1):\n",
    "subject_id_start = 1\n",
    "subject_id_end = 18\n",
    "score_dict = {}\n",
    "tmv_classifier_record = {}\n",
    "tmv_result_dict_all_subjects = {}\n",
    "\n",
    "for i in range(subject_id_start, subject_id_end):\n",
    "    tasks_dict_record = {}\n",
    "    tasks_dict.clear() # array of dictionaries\n",
    "    for task_rank in range(30):\n",
    "        key_name = \"task\" + str(task_rank+1)\n",
    "        tasks_dict[key_name] = []\n",
    "    subject_id = i\n",
    "    score_dict[str(subject_id)] = {}\n",
    "    tmv_classifier_record[subject_id] = []\n",
    "    print()\n",
    "    print(\"checking subject\",subject_id)\n",
    "    print()\n",
    "    frame = []\n",
    "    for session in range(1,7):\n",
    "        data_one = pd.read_csv('data_preprocess/'+data_status + data_source+'_plateau_removed_data/'+data_source+\"_subject_\"+str(subject_id)+\"_session_\"+str(session)+\".csv\",\n",
    "                      header = None)\n",
    "        zeros = [0] * 20\n",
    "\n",
    "        if len(data_one) <= 3000:\n",
    "            data_one.loc[len(data_one)] = zeros\n",
    "        data_one = data_one.iloc[0:3000]\n",
    "        temp_frame = []\n",
    "        for i in range(5):\n",
    "            temp = data_one.iloc[int(i * 600 + first_chopped_off) : int((i + 1) * 600 - last_chopped_off)]\n",
    "            temp_frame.append(temp)\n",
    "        data_one = pd.concat(temp_frame)\n",
    "        frame.append(data_one)\n",
    "    data = pd.concat(frame)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # check plateau (noise)\n",
    "    index_to_be_removed = []\n",
    "    for session in range(0,6):\n",
    "        temp_data = data.iloc[session * 2100 : (session + 1) * 2100]\n",
    "        for move in range(0,5):\n",
    "            move_data = temp_data.iloc[move * 420 : (move + 1) * 420]\n",
    "            for i in range(len(move_data)):\n",
    "                lst = move_data.iloc[i, :].tolist()\n",
    "                if sum(lst) == 0:\n",
    "                    index_to_be_removed.append(session * 2100 + move * 420 + i)\n",
    "    print(\"number of rows to be removed is\", len(index_to_be_removed))\n",
    "    \n",
    "    # add labels\n",
    "    ones = [1] * int(600 * 0.7)\n",
    "    twos = [2] * int(600 * 0.7)\n",
    "    threes = [3] * int(600 * 0.7)\n",
    "    fours = [4] * int(600 * 0.7)\n",
    "    fives = [5] * int(600 * 0.7)\n",
    "    len(fives)\n",
    "    session1 = ones + twos + threes + fours + fives\n",
    "    session2 = fours + ones + twos + threes + fives\n",
    "    session3 = ones + fours + threes + twos + fives\n",
    "    session4 = ones + twos + threes + fours + fives\n",
    "    session5 = twos + ones + threes + fives + fours\n",
    "    session6 = ones + twos + fours + threes + fives\n",
    "    session_all = session1 + session2 + session3 + session4 + session5 + session6\n",
    "    data[\"ground_truth\"] = session_all\n",
    "    \n",
    "    #check if the subject should be kept\n",
    "    percentage_removed_total = (int(18000 * 0.7) - len(index_to_be_removed)) / 18000.0\n",
    "    print(\"percentage of data left for subject\", subject_id, \"is\", percentage_removed_total)\n",
    "    if percentage_removed_total < 0.35:\n",
    "        print(\"the subject\", subject_id, \"should be removed and will be ignored\")\n",
    "        continue\n",
    "    if str(subject_id) not in subject_unknown_percentage:\n",
    "        subject_unknown_percentage[str(subject_id)] = {}\n",
    "    subject_unknown_percentage[str(subject_id)][\"known\"] = percentage_removed_total \n",
    "    subject_preprocess_record[str(subject_id)] = {}\n",
    "        \n",
    "    # checks each six session:\n",
    "    print(\"check session for subject\", subject_id)\n",
    "    session_list = [i for i in range(0, 6)]\n",
    "    for session in range(0, 6):\n",
    "        session_lowerbound = 2100 * session\n",
    "        session_upperbound = 2100 * (session + 1)\n",
    "        to_be_removed = [i for i in index_to_be_removed if i >= session_lowerbound and i < session_upperbound]\n",
    "        print(\"Number of rows to be removed for session\", (session + 1) , \"is\", len(to_be_removed))\n",
    "        percentage_remained = (2100 - (len(to_be_removed))) / 3000.0\n",
    "        print(\"percent of rows left in sesssion\", (session + 1), \"is\", percentage_remained)\n",
    "        if percentage_remained < 0.35:\n",
    "            session_list.remove(session)\n",
    "            print(\"session \" + str(session + 1) + \" should be removed and will be ignored\")\n",
    "            print()\n",
    "        print()\n",
    "    if len(session_list) == 0:\n",
    "        print(\"all sessions are ignored. Continue to next person\")\n",
    "        continue\n",
    "    \n",
    "    subject_preprocess_record[str(subject_id)][\"session_remained\"] = len(session_list)\n",
    "    \n",
    "    not_session_list = [i for i in range(0, 6) if i not in session_list]\n",
    "    for i in not_session_list:\n",
    "        for j in range(i*5, (i+1)*5):\n",
    "            print(\"j is\",j)\n",
    "            tasks_dict[\"task\"+str(j+1)].extend([-1]*420)\n",
    "    # cut 7 folds\n",
    "    test1data = []\n",
    "    test2data = []\n",
    "    test3data = []\n",
    "    test4data = []\n",
    "    test5data = []\n",
    "    test6data = []\n",
    "    test7data = []\n",
    "    removed_dict = {}\n",
    "    fold_names = [\"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\", \"fold6\", \"fold7\"]\n",
    "    fold_names_dict = {}\n",
    "    for i in range(len(fold_names)):\n",
    "        name = fold_names[i]\n",
    "        fold_names_dict[name] = i + 1\n",
    "#     print(\"the fold_names_dict is\", fold_names_dict)\n",
    "    # for each move (420 lines), split the data into seven folds\n",
    "    # at the same time, record the number of lines being that would be omited\n",
    "    # remove folds that have less than 33.33% data remained\n",
    "    #each fold should have at most 60 * 30 = 1800 (originally 2571.4)\n",
    "    move_lst = []\n",
    "    for ele in session_list:\n",
    "        temp = [i for i in range(ele*5, (ele + 1)*5)]\n",
    "        move_lst.extend(temp)\n",
    "    for i in move_lst:\n",
    "        lowerBound = i * 420\n",
    "        test1data.append(data.iloc[lowerBound : lowerBound + 60])\n",
    "        check_removed_index(\"fold1\", removed_dict, index_to_be_removed, lowerBound, lowerBound + 60)\n",
    "        test2data.append(data.iloc[lowerBound + 60 : lowerBound + 120])\n",
    "        check_removed_index(\"fold2\", removed_dict, index_to_be_removed, lowerBound + 60, lowerBound + 120)\n",
    "        test3data.append(data.iloc[lowerBound + 120 : lowerBound + 180])\n",
    "        check_removed_index(\"fold3\", removed_dict, index_to_be_removed, lowerBound + 120, lowerBound + 180)\n",
    "        test4data.append(data.iloc[lowerBound + 180 : lowerBound + 240])\n",
    "        check_removed_index(\"fold4\", removed_dict, index_to_be_removed, lowerBound + 180, lowerBound + 240)\n",
    "        test5data.append(data.iloc[lowerBound + 240 : lowerBound + 300])\n",
    "        check_removed_index(\"fold5\", removed_dict, index_to_be_removed, lowerBound + 240, lowerBound + 300)\n",
    "        test6data.append(data.iloc[lowerBound + 300 : lowerBound + 360])\n",
    "        check_removed_index(\"fold6\", removed_dict, index_to_be_removed, lowerBound + 300, lowerBound + 360)\n",
    "        test7data.append(data.iloc[lowerBound + 360 : lowerBound + 420])\n",
    "        check_removed_index(\"fold7\", removed_dict, index_to_be_removed, lowerBound + 360, lowerBound + 420)\n",
    "\n",
    "    folds_list = [test1data, test2data, test3data, test4data, test5data, test6data, test7data]\n",
    "    # check folds percentages\n",
    "    for name in fold_names:\n",
    "        removed_num = removed_dict[name]\n",
    "        remained_percentage = (((2100 * len(session_list))/ 7.0) - removed_num) / ((3000 * len(session_list)) / 7.0)\n",
    "        print()\n",
    "        print(\"the \" + name + \" has\", remained_percentage, \"left\")\n",
    "        print()\n",
    "        if remained_percentage < 0.35:\n",
    "            print(name + \" should be removed for subject\", subject_id)\n",
    "            idx = fold_names.index(name)\n",
    "            print(\"the index to be removed is\", idx)\n",
    "            del folds_list[idx]\n",
    "            fold_names.remove(name)\n",
    "    folds = []\n",
    "    print(removed_dict)\n",
    "    print(sum(removed_dict.values()))\n",
    "    for fold in folds_list:\n",
    "        data = pd.concat(fold)\n",
    "        print(data.shape)\n",
    "        folds.append(data)\n",
    "    if len(folds) == 0:\n",
    "        print(\"all folds are ignored. Continue to next person\")\n",
    "        continue\n",
    "    \n",
    "    folds_predicted_lst = []\n",
    "    subject_preprocess_record[str(subject_id)][\"folds_remained\"] = len(folds)\n",
    "    \n",
    "    t_start = time()\n",
    "    subject_prediction[str(subject_id)] = {}\n",
    "    models = zip(names, classifiers, dicts_records)\n",
    "    best_classifier_predicted_y.clear()\n",
    "    second_classifier_predicted_y.clear()\n",
    "    for name, classifier, dicts_record in models:\n",
    "        for key in tasks_dict:\n",
    "            if len(tasks_dict[key]) > 0 and tasks_dict[key].count(-1) == 420:\n",
    "                continue\n",
    "            else:\n",
    "                tasks_dict[key] = []\n",
    "        \n",
    "        folds_predicted_lst.clear()\n",
    "        accuracy = 0\n",
    "        t0 = time()\n",
    "        execute_counter = 1\n",
    "        for i in range(len(folds_list)):\n",
    "            folds.append(folds.pop(0)) # move the first fold to the last, and iterate it 7 times\n",
    "            data = pd.concat(folds[:-1])\n",
    "            X = data.iloc[:, :-1]\n",
    "            y = data.iloc[:, -1]\n",
    "            clf = classifier\n",
    "            clf.fit(X,y)\n",
    "            data_test = folds[-1]\n",
    "            X_test = data_test.iloc[:, :-1]\n",
    "            y_test = data_test.iloc[:, -1]\n",
    "            y_predict = []\n",
    "            if name == \"GradientBoostingRegressor\":\n",
    "                y_predict = clf.predict(X_test)\n",
    "                accuracy = accuracy + clf.score(X_test, y_test)\n",
    "            else:\n",
    "                y_predict = clf.predict(X_test)\n",
    "                folds_predicted_lst.append(y_predict)\n",
    "                print(\"executed\",execute_counter,\"times\")\n",
    "                accuracy = accuracy + calculate_accuracy(y_test.tolist(), y_predict)\n",
    "            execute_counter += 1\n",
    "        t1 = time()\n",
    "        time_elapsed = t1 - t0\n",
    "        print()\n",
    "        print(\"The time it takes to run \" + name + \" is\", time_elapsed)\n",
    "        if name not in time_classifier:\n",
    "            time_classifier[name] = 0\n",
    "        time_classifier[name] = time_classifier[name] + time_elapsed\n",
    "        accuracy = accuracy / float(len(folds_list))\n",
    "        subject_prediction[str(subject_id)][name] = {}\n",
    "        subject_prediction[str(subject_id)][name][\"acutual_y\"] = y_test\n",
    "        subject_prediction[str(subject_id)][name][\"predicted_y\"] = y_predict\n",
    "        dicts_record[str(subject_id)]= accuracy\n",
    "        \n",
    "        score_dict[str(subject_id)][name] = accuracy\n",
    "        print(\"The accuracy of subject\", subject_id, \"is\", accuracy, \"with the model \" + name)\n",
    "\n",
    "        print()\n",
    "        print(\"length of the folds_predicted_lst for \" + name + \" is\", len(folds_predicted_lst))\n",
    "        print()\n",
    "\n",
    "        fold_new_names = [\"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\", \"fold6\", \"fold7\"]\n",
    "        folds_predicted_lst_counter = 0\n",
    "        for fold_name in fold_new_names:\n",
    "            if fold_name in fold_names:\n",
    "                print(fold_name + \" is in!\")\n",
    "   \n",
    "                task_counter = 0\n",
    "                temp_lst = folds_predicted_lst[folds_predicted_lst_counter]\n",
    "                for key in tasks_dict:\n",
    "                    if len(tasks_dict[key]) > 0 and tasks_dict[key].count(-1) == 420:\n",
    "                        print(key + \" has been ignored, probably due to the ignored session of the subject\", subject_id)\n",
    "                        continue\n",
    "                    tasks_dict[key].extend(temp_lst[task_counter * 60: (task_counter + 1)*60])\n",
    "                    task_counter = task_counter + 1\n",
    "                folds_predicted_lst_counter += 1\n",
    "            else:\n",
    "                print(fold_name + \" is not in!\")\n",
    "                for key in tasks_dict:\n",
    "                    if len(tasks_dict[key]) > 0 and tasks_dict[key].count(-1) == 420:\n",
    "                        print(key + \" has been ignored, probably due to the ignored session of the subject\", subject_id)\n",
    "                        continue\n",
    "                    tasks_dict[key].extend([-1]*60)\n",
    "            \n",
    "\n",
    "#         print()\n",
    "#         print(\"Printing tasks_dict\")\n",
    "#         count = 1\n",
    "#         for key in tasks_dict:\n",
    "#             print(str(count) + \" \" + str(len(tasks_dict[key])))\n",
    "#             count += 1\n",
    "#         print()\n",
    "        \n",
    "        tasks_dict_copy = tasks_dict.copy()\n",
    "        tasks_dict_record[name] = tasks_dict_copy\n",
    "        \n",
    "#         if name == \"RandomForest\":\n",
    "#             for key in tasks_dict:\n",
    "#                 best_classifier_predicted_y.extend(tasks_dict[key])\n",
    "\n",
    "#             print()\n",
    "#             print(\"The predicted_y length of the \"+ name + \" is\", len(best_classifier_predicted_y))\n",
    "#             print()\n",
    "#         if name == \"RBF SVM\":\n",
    "#             for key in tasks_dict:\n",
    "#                 second_classifier_predicted_y.extend(tasks_dict[key])\n",
    "\n",
    "#             print()\n",
    "#             print(\"The predicted_y length of the \"+ name + \" is\", len(second_classifier_predicted_y))\n",
    "#             print()       \n",
    "        \n",
    "        \n",
    "#         print(\"=\"*20)\n",
    "#         print()\n",
    "    \n",
    "    print(\"print tasks_dict_record\")\n",
    "    for key in tasks_dict_record:\n",
    "        print(key)\n",
    "        print(len(tasks_dict_record[key]))\n",
    "        print(\"=\"*20)\n",
    "    classifier_name_order = names.copy()\n",
    "    print(score_dict)\n",
    "    print(score_dict[str(subject_id)][\"RBF SVM\"])\n",
    "    print(\"Test!\"*20)\n",
    "    classifier_name_order.sort(key=lambda x: score_dict[str(subject_id)][x], reverse=True)\n",
    "    classifiers_TMV = classifier_name_order[:2]\n",
    "    tmv_classifier_record[subject_id].extend(classifiers_TMV)\n",
    "    print(\"classifiers that will perform TMV are\", classifiers_TMV)\n",
    "\n",
    "    name_one = classifiers_TMV[0]\n",
    "    index_one = names.index(name_one)\n",
    "    name_two = classifiers_TMV[1]\n",
    "    index_two = names.index(name_two)\n",
    "    \n",
    "    model_1_task_dict = tasks_dict_record[name_one]\n",
    "    model_2_task_dict = tasks_dict_record[name_two]\n",
    "    print(\"model_1_task_dict\", len(model_1_task_dict))\n",
    "    print(\"model_2_task_dict\", len(model_2_task_dict))\n",
    "    for key in model_1_task_dict:\n",
    "        best_classifier_predicted_y.extend(model_1_task_dict[key])\n",
    "    \n",
    "    for key in model_2_task_dict:\n",
    "        second_classifier_predicted_y.extend(model_2_task_dict[key])\n",
    "        \n",
    "    print(len(best_classifier_predicted_y))\n",
    "    print(\"=\"*20)\n",
    "    print(len(second_classifier_predicted_y))\n",
    "    tep = 0\n",
    "    for i in range(len(best_classifier_predicted_y)):\n",
    "        if second_classifier_predicted_y[i] == best_classifier_predicted_y[i]:\n",
    "            tep += 1\n",
    "    print(\"same is \", tep)\n",
    "    print(\"Test!\"*10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Time Majority Voting\n",
    "    task_ground_truth = 1\n",
    "    interval_lst = [(0, 419), (420, 839), (840, 1259), (1260, 1679), (1680, 2099)]\n",
    "\n",
    "    table_data = defaultdict(list)\n",
    "    print(subject_id)\n",
    "    table_data = defaultdict(list)\n",
    "    task_lst = []\n",
    "    task_lst.append([1,2,1,1,2,1]) # task 1\n",
    "    task_lst.append([2,3,4,2,1,2]) # task 2\n",
    "    task_lst.append([3,4,3,3,3,4]) # task 3\n",
    "    task_lst.append([4,1,2,4,5,3]) # task 4\n",
    "    task_lst.append([5,5,5,5,4,5]) # task 5\n",
    "    tasks_idx = [[],[],[],[],[]]\n",
    "    should_be_ignored_lists = [[],[],[],[],[]]\n",
    "\n",
    "    task_count = 1\n",
    "    subject_accuracy_before_numerator = 0\n",
    "    subject_accuracy_before_denominator = 0\n",
    "    subject_accuracy_numerator = 0\n",
    "    subject_accuracy_denominator = 0\n",
    "    \n",
    "    data_used = 0\n",
    "    \n",
    "    tmv_result_dict = {}\n",
    "    for task_num, task_idx, ignored_lst in zip(task_lst, tasks_idx, should_be_ignored_lists):\n",
    "        tmv_result_dict[str(task_count)] = []\n",
    "        for i in range(len(task_num)):\n",
    "            starting = 2100 * i\n",
    "            pos = task_num[i]\n",
    "            interval = interval_lst[pos - 1]\n",
    "            idx_first = starting + interval[0]\n",
    "            idx_second = starting + interval[1]\n",
    "            task_idx.append((idx_first, idx_second))\n",
    "\n",
    "        print(\"Task \" + str(task_count) + \" tasks indices\")\n",
    "        print(task_idx)\n",
    "        print()\n",
    "\n",
    "        session_count = 1\n",
    "        i = 0\n",
    "        length = len(task_idx)\n",
    "        session_map = {}\n",
    "\n",
    "        while i < length:\n",
    "            \n",
    "            interval = task_idx[i]\n",
    "            session_map[interval] = session_count\n",
    "            session = best_classifier_predicted_y[interval[0] : interval[1]+1]\n",
    "#             print(\"Testing session length is\", len(session))\n",
    "            session = [i for i in session if i != -1]\n",
    "#             print(\"Testing after-session length is\", len(session))\n",
    "            matched_total = len([i for i in session if i == task_ground_truth])\n",
    "            if(len(session) == 0):\n",
    "                session.append(10)\n",
    "            ground_truth_percentage = matched_total / len(session)\n",
    "            print(\"session \" + str(session_count) + \" has percentage to the ground truth: \" + str(ground_truth_percentage))\n",
    "            print()\n",
    "            if ground_truth_percentage < ignore_session_threashold:\n",
    "                print(\"session \" + str(session_count) + \" should be ignored for the task_\" + str(task_count))\n",
    "                print()\n",
    "                ignored_lst.append(interval)\n",
    "            i += 1\n",
    "            session_count += 1\n",
    "\n",
    "        print(\"new task_\" + str(task_count) + \"_idx is\", task_idx)\n",
    "        print()\n",
    "        print(session_map)\n",
    "        print()\n",
    "        print(\"Ignored intervals:\", ignored_lst)\n",
    "        print()\n",
    "\n",
    "        total_accuracy_before_numerator = 0\n",
    "        total_accuracy_before_denominator = 0\n",
    "        total_accuracy_new_numerator = 0\n",
    "        total_accuracy_new_denominator = 0\n",
    "        task_tmp_before = []\n",
    "        task_tmp_new = []\n",
    "        for ele in task_idx: \n",
    "            if ele in ignored_lst:\n",
    "                task_tmp_before.append(-1)\n",
    "                task_tmp_new.append(-1)\n",
    "                tmv_result_dict[str(task_count)].extend([-1]*420)\n",
    "                continue\n",
    "            session_num = session_map[ele]\n",
    "            best_classifier = best_classifier_predicted_y[ele[0] : ele[1] + 1]\n",
    "            best_classifier_copy = best_classifier_predicted_y[ele[0] : ele[1] + 1]\n",
    "\n",
    "            second_classifier = second_classifier_predicted_y[ele[0] : ele[1] + 1]\n",
    "            second_classifier_copy = second_classifier_predicted_y[ele[0] : ele[1] + 1]\n",
    "            \n",
    "            best_classifier = [i for i in best_classifier if i != -1]\n",
    "            data_used += len(best_classifier)\n",
    "            print()\n",
    "            second_classifier = [j for j in second_classifier if j != -1]\n",
    "\n",
    "            majority_prediction = most_common(best_classifier)\n",
    "            print(\"majority_prediction is\", majority_prediction)\n",
    "            print()\n",
    "            y_predict = []\n",
    "            for j in range(len(best_classifier_copy)):\n",
    "                if best_classifier_copy[j] == second_classifier_copy[j]:\n",
    "                    tmv_result_dict[str(task_count)].append(best_classifier_copy[j])\n",
    "                else:\n",
    "                    tmv_result_dict[str(task_count)].append(majority_prediction)\n",
    "            for i in range(len(best_classifier)):\n",
    "                if best_classifier[i] == second_classifier[i]:\n",
    "                    y_predict.append(best_classifier[i])\n",
    "                else:\n",
    "                    y_predict.append(majority_prediction)\n",
    "            before_matched_predict = [j for j in best_classifier if j == task_ground_truth]\n",
    "            before_accuracy = len(before_matched_predict) / len(best_classifier)\n",
    "            task_tmp_before.append(before_accuracy)\n",
    "            total_accuracy_before_numerator += len(before_matched_predict)\n",
    "            total_accuracy_before_denominator += len(best_classifier)\n",
    "            print(\"session\", session_num, \"had the prediction accuracy before\", before_accuracy)\n",
    "            print()\n",
    "            matched_predict = [j for j in y_predict if j == task_ground_truth]\n",
    "            accuracy = len(matched_predict) / len(y_predict)\n",
    "            task_tmp_new.append(accuracy)\n",
    "            total_accuracy_new_numerator += len(matched_predict)\n",
    "            total_accuracy_new_denominator += len(y_predict)\n",
    "            print(\"session\", session_num, \"has the prediction accuracy\", accuracy)\n",
    "\n",
    "        tmv_result_dict_all_subjects[subject_id] = tmv_result_dict\n",
    "        total_accuracy_before = accuracy_divide(total_accuracy_before_numerator, total_accuracy_before_denominator)\n",
    "        subject_accuracy_before_numerator += total_accuracy_before_numerator\n",
    "        subject_accuracy_before_denominator += total_accuracy_before_denominator\n",
    "\n",
    "        total_accuracy_new = accuracy_divide(total_accuracy_new_numerator, total_accuracy_new_denominator)\n",
    "\n",
    "        subject_accuracy_numerator += total_accuracy_new_numerator\n",
    "        subject_accuracy_denominator += total_accuracy_new_denominator\n",
    "\n",
    "\n",
    "        task_tmp_before.append(total_accuracy_before)\n",
    "        task_tmp_new.append(total_accuracy_new)\n",
    "        key_name_before = \"task\"+str(task_count)+\"before\"\n",
    "        key_name_new = \"task\"+str(task_count)+\"new\"\n",
    "        table_data[key_name_before] = task_tmp_before\n",
    "        table_data[key_name_new] = task_tmp_new\n",
    "        task_count = task_count + 1\n",
    "        task_ground_truth += 1\n",
    "        print(\"=\"*30)\n",
    "        print()\n",
    "\n",
    "    t_end = time()\n",
    "    time_elapsed_TC = t_end - t_start \n",
    "    time_continuity_subject[subject_id] = time_elapsed_TC\n",
    "\n",
    "    subject_accuracy_before = accuracy_divide(subject_accuracy_before_numerator, subject_accuracy_before_denominator)\n",
    "#     subject_accuracy_before = subject_accuracy_before_numerator / subject_accuracy_before_denominator\n",
    "    subject_accuracy_best_classifier_dict[str(subject_id)] = subject_accuracy_before\n",
    "    print()\n",
    "    print(str(subject_id) + \"'s best classifier (\"+ name_one +\")has accuracy of \" + str(subject_accuracy_before))\n",
    "    print()\n",
    "    subject_accuracy = accuracy_divide(subject_accuracy_numerator, subject_accuracy_denominator)\n",
    "#     subject_accuracy = subject_accuracy_numerator / subject_accuracy_denominator\n",
    "    subject_accuracy_tmv_dict[str(subject_id)] = subject_accuracy\n",
    "    print()\n",
    "    print(str(subject_id) + \"'s time continuity algorithm has accuracy of \" + str(subject_accuracy))\n",
    "    print()\n",
    "    print(\"Table data currently is\")\n",
    "    print(table_data)\n",
    "\n",
    "    for key in table_data:\n",
    "        lst = table_data[key]\n",
    "        new_ls = [round(i, 3) for i in lst]\n",
    "        table_data[key] = new_ls\n",
    "\n",
    "    idx_lst = []\n",
    "    for i in range(1, 7):\n",
    "        idx_lst.append(\"session\"+str(i))\n",
    "    idx_lst.append(\"accuracy\")\n",
    "    df = pd.DataFrame(table_data, index=idx_lst)\n",
    "    df.to_csv(\"Time_Majority_results/\"+data_source+\"/subject_\"+str(subject_id)+\"_all_tasks.csv\")\n",
    "\n",
    "    print()\n",
    "    print(str(subject_id) + \" spent \" + str(time_elapsed_TC) + \" execute Time_continuity\")\n",
    "    data_left_for_subjects[subject_id] = data_used / 18000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eaecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmv_classifier_record)\n",
    "print()\n",
    "print(\"Time continuity subject dictionary is\", time_continuity_subject)\n",
    "print()\n",
    "print(\"subject accuracy_Best_classifier\", subject_accuracy_best_classifier_dict)\n",
    "print()\n",
    "print(\"subject accuracy_TMV\", subject_accuracy_tmv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data percentage left for all subjects\", data_left_for_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dicts_order is:\")\n",
    "names.append(\"subject's best classifier\")\n",
    "dicts_records.append(subject_accuracy_best_classifier_dict)\n",
    "names.append(\"TMV\")\n",
    "dicts_records.append(subject_accuracy_tmv_dict)\n",
    "for name, dicts_record in zip(names, dicts_records):\n",
    "    print(name)\n",
    "    print(dicts_record)\n",
    "    print()\n",
    "print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98eca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This block rearranges the result of different classfiers based on the accuracy, and sort subject id's based on the \n",
    "# classifier that performed the best\n",
    "print(dicts_records)\n",
    "dict_sum_recorder = {}\n",
    "for name, dicts_record in zip(names, dicts_records):\n",
    "    cur = sum(dicts_record.values())\n",
    "    dict_sum_recorder[name] = cur\n",
    "dict_sum_recorder = dict(sorted(dict_sum_recorder.items(), key=lambda item: -item[1]))\n",
    "print(\"The dic_sum_recorder is\")\n",
    "print(dict_sum_recorder)\n",
    "print()\n",
    "classifier_order = list(dict_sum_recorder.keys())\n",
    "print(\"the order of the classifier is: \")\n",
    "print(classifier_order)\n",
    "print()\n",
    "best_classifier_name = classifier_order[0]\n",
    "print(\"The best classifier is: \" + best_classifier_name)\n",
    "best_classifier_dict = dicts_records[names.index(best_classifier_name)]\n",
    "print(\"the dictionary for the best classifier is: \")\n",
    "print(best_classifier_dict)\n",
    "print()\n",
    "\n",
    "best_classifier_dict_sorted = dict(sorted(best_classifier_dict.items(), key=lambda item: -item[1]))\n",
    "subject_id_order = list(best_classifier_dict_sorted.keys()) # The x axis of the plot\n",
    "print(\"best_classifier_dict_sorted is: \")\n",
    "print(best_classifier_dict_sorted)\n",
    "print()\n",
    "print(\"The order of the subject id is\")\n",
    "print(subject_id_order)\n",
    "print()\n",
    "\n",
    "result_y_res = [] # each element follows the order of the classifier_order\n",
    "for i in range(len(classifier_order)):\n",
    "    temp_lst = []\n",
    "    classifier = classifier_order[i]\n",
    "    print(classifier)\n",
    "    for subject in subject_id_order:\n",
    "        idx = names.index(classifier)\n",
    "        print(idx)\n",
    "        print(dicts_records[idx][subject])\n",
    "        temp_lst.append(dicts_records[idx][subject])\n",
    "        print(\"=\"*10)\n",
    "    result_y_res.append(temp_lst)\n",
    "\n",
    "print(result_y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject_id_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_order.reverse()\n",
    "print(subject_id_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75182c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Time continuity subject dictionary is\", time_continuity_subject)\n",
    "print()\n",
    "print(\"subject accuracy for their best classifier\", subject_accuracy_best_classifier_dict)\n",
    "print()\n",
    "print(\"subject accuracy_TMV\", subject_accuracy_tmv_dict)\n",
    "\n",
    "\n",
    "# subject_id_order = [10, 12, 13, 15, 8, 17, 14, 2, 3, 5, 9, 1]\n",
    "# subject_id_order = [1,2,3,4]\n",
    "# subject_id_order = [z for z in range(subject_id_start, subject_id_end)] \n",
    "# subject_id_order.sort(key = lambda x : subject_accuracy_best_classifier_dict[x], reverse=True)\n",
    "plt.figure(figsize=(10, 5))\n",
    "best_classifier_predict = []\n",
    "New_predict = []\n",
    "percentage_left_subjects = []\n",
    "time_data = []\n",
    "for num in subject_id_order:\n",
    "    best_classifier_predict.append(subject_accuracy_best_classifier_dict[num])\n",
    "    New_predict.append(subject_accuracy_tmv_dict[num])\n",
    "    percentage_left_subjects.append(data_left_for_subjects[int(num)])\n",
    "    time_data.append(time_continuity_subject[int(num)])\n",
    "    \n",
    "RF_Phase2_accuracy = sum(best_classifier_predict) / len(best_classifier_predict)\n",
    "TMV_accuracy = sum(New_predict) / len(New_predict)\n",
    "print(\"=\"*20)\n",
    "print(\"best_classifier_accuracy\", RF_Phase2_accuracy)\n",
    "print(\"TMV_accuracy\", TMV_accuracy)\n",
    "print(\"=\"*20)\n",
    "print()\n",
    "print(\"len of the time data\", len(time_data))\n",
    "X_axis = np.arange(len(subject_id_order))\n",
    "plt.bar(X_axis - 0.2, best_classifier_predict, 0.4, label = 'Best classifier Accuracy', color = '#FFC0CB')\n",
    "plt.bar(X_axis + 0.2, New_predict, 0.4, label = 'TMV Accuracy', color = '#ADD8E6')\n",
    "plt.plot(X_axis, percentage_left_subjects, marker='D', label = 'Data Remained', color = \"#0343DF\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "print(labels)\n",
    "order=[2,1,0]\n",
    "plt.xticks(X_axis, subject_id_order)\n",
    "plt.xlabel('Subject ID orderd by TMV', fontsize=15)\n",
    "plt.ylabel('Accuracy and Data Remained', fontsize=15)\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], fontsize=10, loc=0) \n",
    "plt.savefig(\"Time_Majority_results/\"+data_source+\"/Accuracy_all_subjects.jpg\", bbox_inches='tight', dpi = 1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00469ebf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_axis = subject_id_order\n",
    "print(x_axis)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(result_y_res)):\n",
    "    result_y_res[i].reverse()\n",
    "    y = result_y_res[i]\n",
    "    label_name = classifier_order[i]\n",
    "    temp_avg = dict_sum_recorder[label_name] / float(len(subject_id_order))\n",
    "    temp_avg = round(temp_avg, 2)\n",
    "    if label_name == \"subject's best classifier\":\n",
    "        label_name = \"best classifier(Phase 2)\"\n",
    "    if label_name == 'GradientBoosting':\n",
    "        label_name = 'GradientBoost'\n",
    "    if label_name == 'SLDA':\n",
    "        label_name = 'sLDA'\n",
    "    ax.plot(x_axis, y, marker='D', label = label_name + \"(\" + str(temp_avg)+\")\")\n",
    "\n",
    "ax.set_position([0.1,0.5, 1.2, 1.0])\n",
    "ax.legend(loc='upper left')\n",
    "plt.axhline(y=0.2, color='r', linestyle=':')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Subject ID orderd by ' + best_classifier_name + \" Phase 1\", fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "# plt.figure(figsize=(5, 5))\n",
    "plt.savefig(\"Time_Majority_results/\"+data_source+\"/algorithm_comparison_each_subject.jpg\", bbox_inches='tight', dpi = 1500)\n",
    "# plt.savefig(data_source + \"_\" +data_status+\"results/algorithm_comparison_each_subject.jpg\", bbox_inches='tight', dpi = 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f4437",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TMV_avg_runtime = sum(time_data)/len(time_data)\n",
    "print(\"TMV_avg_runtime\",TMV_avg_runtime)\n",
    "print()\n",
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax1 = plt.subplots()\n",
    "known = []\n",
    "for i in subject_id_order:\n",
    "    known.append(subject_unknown_percentage[str(i)][\"known\"])\n",
    "print(\"known percentage\", known)\n",
    "ax2 = ax1.twinx()\n",
    "lns1 = ax1.plot(X_axis, known, marker='D', label = 'Train Data Remained', color = \"#0343DF\")\n",
    "lns2 = ax2.plot(X_axis, time_data, marker='D', label = 'Runtime', color='#FF796C')\n",
    "ax1.set_ylabel('Data Remained Percentage', fontsize=15)\n",
    "ax2.set_ylabel('Time(s)', fontsize=15)\n",
    "\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=0)\n",
    "ax1.set_xlabel('Subject ID orderd by RandomForest Phase 1', fontsize=15)\n",
    "plt.xticks(X_axis, subject_id_order)\n",
    "plt.savefig(\"Time_Majority_results/\"+data_source+\"/Data_Time.jpg\", bbox_inches='tight', dpi = 1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672fde5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_spent_all_subjects = []\n",
    "id_order_temp = subject_id_order[::-1]\n",
    "for num in id_order_temp:\n",
    "    time_spent_all_subjects.append(time_continuity_subject[int(num)])\n",
    "time_spent_all_subjects = [round(i,3) for i in time_spent_all_subjects]\n",
    "\n",
    "percentage_left_subjects = [round(j,3) for j in percentage_left_subjects]\n",
    "\n",
    "data_time_elapsed = {\"Code Runtime (s)\": time_spent_all_subjects, \"Percent of data left %\": percentage_left_subjects}\n",
    "\n",
    "df = pd.DataFrame(data_time_elapsed, index = id_order_temp)\n",
    "df.to_csv(\"Time_Majority_results/\"+data_source+\"/Runtime_all_subjects.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd340978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record algorithm running time (new graph 3 rows: first row: mean accuracy)\n",
    "#     accuracy code_runtime(s) (排序 based on accuracy)\n",
    "# rf 0.56     15\n",
    " \n",
    "# lda 0.4     xx\n",
    "\n",
    "# adaboost 0.3 xx\n",
    "print(time_continuity_subject)\n",
    "print(\"=\"*20)\n",
    "tmv_average_time = sum(time_continuity_subject.values()) / float(len(subject_id_order))\n",
    "print(tmv_average_time)\n",
    "\n",
    "time_classifier[\"TMV\"] = tmv_average_time\n",
    "avg_accuracy = []\n",
    "time = []\n",
    "name_list = []\n",
    "print(\"The time_classifier is\", time_classifier)\n",
    "print(\"The dict_sum_recorder is\", dict_sum_recorder)\n",
    "print(\"Number of subjects is\", len(subject_id_order))\n",
    "for ele in dict_sum_recorder:\n",
    "    if ele == \"subject's best classifier\":\n",
    "        continue\n",
    "    name_list.append(ele)\n",
    "    temp_avg = dict_sum_recorder[ele] / float(len(subject_id_order))\n",
    "    avg_accuracy.append(round(temp_avg, 2))\n",
    "    temp_time = time_classifier[ele] / float(len(subject_id_order))\n",
    "    time.append(round(temp_time, 1))\n",
    "\n",
    "print()\n",
    "print(\"avg accuracy\", avg_accuracy)\n",
    "print(\"time\", time)\n",
    "print(\"name order\", name_list)\n",
    "\n",
    "data = {'Average Accuracy':avg_accuracy, 'Avg code runtime(s)':time}\n",
    "# Creates pandas DataFrame.  \n",
    "df = pd.DataFrame(data, index = name_list)\n",
    "# df.to_csv(data_source + \"_\" +data_status+\"results/accuracy_runtime_classifier.csv\")\n",
    "df.to_csv(\"Time_Majority_results/\"+data_source+\"/accuracy_runtime_classifier.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6117884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tmv_result_dict)\n",
    "# print(tmv_result_dict_all_subjects[subject_id_search])\n",
    "tmv_result_dict = tmv_result_dict_all_subjects[subject_id_search]\n",
    "print(len(tmv_result_dict))\n",
    "for key in tmv_result_dict:\n",
    "    print(key)\n",
    "    print(len(tmv_result_dict[key]))\n",
    "# print(tmv_result_dict[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e099c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_subject_id_search_task_1\n",
    "subject_id_tmv = subject_id_search\n",
    "interval_session_lst = [(0, 420), (420, 840), (840, 1260), (1260, 1680), (1680, 2100), (2100, 2520)]\n",
    "task_num = 1\n",
    "import matplotlib\n",
    "\n",
    "tmv_predicted = tmv_result_dict[str(task_num)]\n",
    "x_axis = [i + 1 for i in range(420)]\n",
    "x_axis = [i/10 for i in x_axis]\n",
    "# print(\"y_axis is\", y_axis)\n",
    "fig, axs = plt.subplots(6, sharex=True, sharey=True, figsize=(25, 18))\n",
    "\n",
    "\n",
    "y_temp_tmv = tmv_predicted[0 : 420]\n",
    "axs[0].plot(x_axis, y_temp_tmv, label = 'Time Majority Voting')\n",
    "axs[0].set_yticklabels(labels=np.arange(-1,6,1), fontsize=15)\n",
    "axs[0].set_title(\"session 1\", fontsize=20)\n",
    "\n",
    "for i in range(1, len(interval_session_lst)):\n",
    "#     print(i)\n",
    "    interval_session = interval_session_lst[i]\n",
    "#     print(interval_session)\n",
    "    y_temp_tmv = tmv_predicted[interval_session[0] : interval_session[1]]\n",
    "#     print(y_temp_tmv)\n",
    "#     print(\"=\"*20)\n",
    "    axs[i].plot(x_axis, y_temp_tmv)\n",
    "    # axs[1].legend(loc=\"upper right\")\n",
    "    axs[i].set_yticklabels(labels=np.arange(-1,6,1), fontsize=15)\n",
    "    axs[i].set_title(\"session \"+str(i + 1), fontsize=20)\n",
    "\n",
    "plt.xticks(np.arange(0, 43, 2),fontsize=20)\n",
    "plt.yticks(np.arange(-1,6,1), fontsize=15)\n",
    "# plt.xticks(fontsize=15)\n",
    "# matplotlib.rc('ytick', fontsize=15) \n",
    "plt.xlabel('Time Span of Task One for Each Session(s)', fontsize=26)\n",
    "fig.legend(fontsize=23, loc=9)\n",
    "plt.savefig(\"Time_Majority_results/\"+data_source+\"/TMV/subject_\"+str(subject_id_tmv)+\"_task_1.jpg\", dpi = 1000) ## Or it's subject_id_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eabe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw heatmap\n",
    "print(\"the length of the tmv_result_dict is\", len(tmv_result_dict))\n",
    "for key in tmv_result_dict:\n",
    "    print(type(key))\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25461965",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = np.zeros((5, 5))\n",
    "for key in tmv_result_dict:\n",
    "    res = []\n",
    "    y = tmv_result_dict[key]\n",
    "    y = [z for z in y if z != -1]\n",
    "    for j in range(1,6):\n",
    "        total_j = len([i for i in y if i == j])\n",
    "        val = total_j / float(len(y))\n",
    "        res.append(float(val))\n",
    "    heatmap_data[int(key) - 1] = res\n",
    "print(heatmap_data)\n",
    "x_axis_labels = [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\"]\n",
    "y_axis_labels = [\"T1:Think\",\"T2:Count\",\"T3:Recall\",\"T4:Breathe\",\"T5:Draw\"]\n",
    "ax = sns.heatmap(heatmap_data, cmap=\"Blues\", vmin= -1, vmax=1, annot=True, fmt=\".2f\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.savefig(\"Time_Majority_results/\"+data_source+\"/TMV/subejct_\"+str(subject_id_tmv)+\"_TMV_heatmap.jpg\", dpi = 800)\n",
    "plt.title(\"subject_\" + str(subject_id_tmv) + \" all six sessions TMV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmv_classifier_record)\n",
    "print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmv_algorithm_first = []\n",
    "tmv_algorithm_second = []\n",
    "ids = []\n",
    "\n",
    "for key in tmv_classifier_record:\n",
    "    algorithms = tmv_classifier_record[key]\n",
    "    if len(algorithms) == 0:\n",
    "        continue\n",
    "    ids.append(key)\n",
    "    tmv_algorithm_first.append(algorithms[0])\n",
    "    tmv_algorithm_second.append(algorithms[1])\n",
    "\n",
    "data_algorithms = {\"First Algorithm Used\":tmv_algorithm_first, \"Second Algorithm Used\":tmv_algorithm_second}\n",
    "df_2 = pd.DataFrame(data_algorithms, index = ids)\n",
    "df_2.to_csv(\"Time_Majority_results/\"+data_source+\"/TMV/classifiers_used_TMV.csv\")\n",
    "print(df_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
